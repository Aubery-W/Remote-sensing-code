{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-8ac6870e3a4d>:113: RuntimeWarning: invalid value encountered in greater\n",
      "  LSE[LSE>0.5]=0.985\n",
      "<ipython-input-1-8ac6870e3a4d>:114: RuntimeWarning: invalid value encountered in less\n",
      "  LSE[LSE<0.1] = 0.96\n",
      "<ipython-input-1-8ac6870e3a4d>:119: RuntimeWarning: invalid value encountered in less\n",
      "  t = (LSE<0.5)&(LSE>0.1)\n",
      "<ipython-input-1-8ac6870e3a4d>:119: RuntimeWarning: invalid value encountered in greater\n",
      "  t = (LSE<0.5)&(LSE>0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-01 04:12 284.4053655582413\n",
      "2008-01-17 04:12 282.74033441450933\n",
      "2008-02-02 04:12 257.15732365588605\n",
      "2008-11-16 04:11 267.9724306851495\n",
      "2008-12-02 04:11 271.7770347537513\n",
      "2008-12-18 04:11 281.6094363130884\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import Nio,os\n",
    "from libtiff import TIFF \n",
    "from osgeo import gdal\n",
    "import Ngl\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "def find_pwvs(pwv,arrlat,arrlon,coor):\n",
    "    latc = np.abs(arrlat-coor[0])\n",
    "    lat_row,lat_li=find_min_pos(latc)\n",
    "    lonc = np.abs(arrlon-coor[1])\n",
    "    lon_row,lon_li=find_min_pos(lonc)\n",
    "#     print(lat_row,lon_li)\n",
    "    return pwv[lat_row][lon_li]\n",
    "def find_bd(data,arrlat,arrlon,coor):\n",
    "    latc = np.abs(arrlat-coor[0])\n",
    "    lat_row,lat_li=find_min_pos(latc)\n",
    "    lonc = np.abs(arrlon-coor[1])\n",
    "    lon_row,lon_li=find_min_pos(lonc)\n",
    "#     print(lat_row,lon_li)\n",
    "    return data[:,lat_row,lon_li]\n",
    "def find_min_pos(arr):\n",
    "    c = np.abs(arr-arr.min())\n",
    "    row = (np.argmin(c))//(c.shape[1])\n",
    "    li = (np.argmin(c))%(c.shape[1])\n",
    "    return row,li\n",
    "\n",
    "def GetCoor(dataset):\n",
    "#     print(\"Driver: {}/{}\".format(dataset.GetDriver().ShortName,\n",
    "#                                 dataset.GetDriver().LongName))\n",
    "#     print(\"Size is {} x {} x {}\".format(dataset.RasterXSize,\n",
    "#                                         dataset.RasterYSize,\n",
    "#                                         dataset.RasterCount))\n",
    "#     print(\"Projection is {}\".format(dataset.GetProjection()))\n",
    "    geotransform = dataset.GetGeoTransform()\n",
    "    if geotransform:\n",
    "#         print(\"Origin = ({}, {})\".format(geotransform[0], geotransform[3]))\n",
    "#         print(\"Pixel Size = ({}, {})\".format(geotransform[1], geotransform[5]))\n",
    "        cor = [[geotransform[0], geotransform[3]],[geotransform[0]+geotransform[1]*dataset.RasterXSize,geotransform[3]+geotransform[5]*dataset.RasterYSize]]\n",
    "#         print(geotransform[0]+geotransform[1]*dataset.RasterXSize,geotransform[3]+geotransform[5]*dataset.RasterYSize)\n",
    "#         print(dataset.ReadAsArray().shape)\n",
    "        lon = np.arange(0,dataset.RasterXSize)\n",
    "        lat = np.arange(0,dataset.RasterYSize)\n",
    "        lat = lat*geotransform[5]+geotransform[3]\n",
    "        lat = np.tile(lat,dataset.RasterXSize)\n",
    "        lat = lat.reshape(dataset.RasterXSize,dataset.RasterYSize)\n",
    "        lat = lat.T\n",
    "        lon = lon*geotransform[1]+geotransform[0]\n",
    "        lon = np.tile(lon,dataset.RasterYSize).reshape(dataset.RasterYSize,dataset.RasterXSize)\n",
    "#         print(lon)\n",
    "        return lat,lon\n",
    "    else:\n",
    "        print(\"No Geotransform\")\n",
    "def Get_PWV(date,time,coor):\n",
    "    path = \"/data/wx_data/2008_pwv_tiff/\"\n",
    "#     time = time.split(\"T\")[1]\n",
    "    time = time.split(\":\")\n",
    "    h = time[0]\n",
    "    m = time[1]\n",
    "    upperf = path+\"2008\"+date.split(\"-\")[1]+date.split(\"-\")[2]+h+\"_pwv.tif\"\n",
    "    lowerf = path+\"2008\"+date.split(\"-\")[1]+date.split(\"-\")[2]+str(int(h)+1).zfill(2)+\"_pwv.tif\"\n",
    "    datasetu = gdal.Open(upperf)\n",
    "    lat ,lon = GetCoor(datasetu)\n",
    "    pwvu = find_pwvs(datasetu.ReadAsArray(),lat,lon,coor)\n",
    "    datasetl = gdal.Open(lowerf)\n",
    "    lat ,lon = GetCoor(datasetl)\n",
    "    pwvl = find_pwvs(datasetl.ReadAsArray(),lat,lon,coor)\n",
    "    pwv = (pwvl-pwvu)*int(m)/60+pwvu\n",
    "#     print(pwv)\n",
    "    return pwv\n",
    "def Get_PWV_Array(date,time,dataset):\n",
    "    latarr,lonarr = GetCoor(dataset)\n",
    "    pwvarr = np.zeros_like(latarr)\n",
    "    path = \"/data/wx_data/2008_pwv_tiff/\"\n",
    "#     time = time.split(\"T\")[1]\n",
    "    time = time.split(\":\")\n",
    "    h = time[0]\n",
    "    m = time[1]\n",
    "    upperf = path+\"2008\"+date.split(\"-\")[1]+date.split(\"-\")[2]+h+\"_pwv.tif\"\n",
    "    lowerf = path+\"2008\"+date.split(\"-\")[1]+date.split(\"-\")[2]+str(int(h)+1).zfill(2)+\"_pwv.tif\"\n",
    "    datasetu = gdal.Open(upperf)\n",
    "    datasetl = gdal.Open(lowerf)\n",
    "    lat ,lon = GetCoor(datasetu)\n",
    "    for i in range(latarr.shape[0]):\n",
    "        for j in range(latarr.shape[1]):\n",
    "            coor=[latarr[i][j],lonarr[i][j]]\n",
    "            pwvu = find_pwvs(datasetu.ReadAsArray(),lat,lon,coor)\n",
    "            pwvl = find_pwvs(datasetl.ReadAsArray(),lat,lon,coor)\n",
    "            pwvarr[i][j] = (pwvl-pwvu)*int(m)/60+pwvu\n",
    "#             print(j)\n",
    "    print(date,h,m,\"PWV Calculated\")\n",
    "    return pwvarr\n",
    "def Calc(dataset,pwv,para):\n",
    "    imga = dataset.ReadAsArray()\n",
    "    imga = np.array(imga,dtype='float64')\n",
    "    imga[imga==0] = np.nan\n",
    "#     B3AP = float(para[0])\n",
    "#     B3MP = float(para[1]) \n",
    "#     B4AP = float(para[2])\n",
    "#     B4MP = float(para[3])\n",
    "#     B3D = np.flipud(imga[0])\n",
    "#     B4D = np.flipud(imga[1])\n",
    "#     B6D = np.flipud(imga[2])\n",
    "#     B3R = B3D*B3MP+B3AP\n",
    "#     B4R = B4D*B4MP+B4AP\n",
    "#     B6R = (B6D-1)*(12.65-3.2)/254+3.2\n",
    "    B3R = np.flipud(imga[0])*0.0001\n",
    "    B4R = np.flipud(imga[1])*0.0001\n",
    "    B6 = np.flipud(imga[2])*0.1\n",
    "    NDVI = (B4R-B3R)/(B4R+B3R)\n",
    "    LSE = NDVI\n",
    "    LSE[LSE>0.5]=0.985\n",
    "    LSE[LSE<0.1] = 0.96\n",
    "    IG = 0\n",
    "    IV = np.max(NDVI)\n",
    "    I = NDVI \n",
    "    PV = (I-0.2)**2/0.09\n",
    "    t = (LSE<0.5)&(LSE>0.1)\n",
    "    t = np.array(t)\n",
    "    LSE[t]= 0\n",
    "    PVS = 0.985*PV+0.96*(1-PV)+(1-0.96)*(1-PV)*0.985*0.55\n",
    "    PVS[~t] = 0\n",
    "    LSE = LSE + PVS\n",
    "    TS = B6\n",
    "    B6R = 666.09/(np.exp(1282.71/TS))-1\n",
    "#     TS = 1282.71/np.log((666.09/B6R+1))\n",
    "    GAM = 1/(14387*B6R/TS**2*(11.45**4*B6R/(1.19104*10**8)+1/11.45))\n",
    "    DEL = -GAM*B6R+TS\n",
    "    w = pwv\n",
    "    F1 = 0.09172*w**2-0.09894*w+1.09659\n",
    "    F2 = -0.71656*w**2-0.64218*w-0.17183\n",
    "    F3 = -0.03503*w**2+1.54063*w-0.46434\n",
    "    TSC = GAM*((F1*B6R+F2)/LSE+F3)+DEL\n",
    "#     plt.contourf(TSC,cmap='gray')\n",
    "#     plt.colorbar()\n",
    "    return TSC\n",
    "def CalcS(dataset,pwv):\n",
    "#     B3AP = float(para[0])\n",
    "#     B3MP = float(para[1]) \n",
    "#     B4AP = float(para[2])\n",
    "#     B4MP = float(para[3])\n",
    "    B3R = dataset[0]*0.0001\n",
    "    B4R = dataset[1]*0.0001\n",
    "    B6T = dataset[2]*0.1\n",
    "#     print(B3R,B4R,B6T,pwv)\n",
    "#     B3R = B3D*B3MP+B3AP\n",
    "#     B4R = B4D*B4MP+B4AP\n",
    "#     B6R = (B6D-1)*(12.65-3.2)/254+3.2\n",
    "    NDVI = (B4R-B3R)/(B4R+B3R)\n",
    "    LSE = NDVI\n",
    "    if(NDVI>0.5):\n",
    "        LSE = 0.985\n",
    "    elif(NDVI<0.1):\n",
    "        LSE = 0.96\n",
    "    else:\n",
    "        I = NDVI \n",
    "        PV = (I-0.2)**2/0.09\n",
    "        PVS = 0.985*PV+0.96*(1-PV)+(1-0.96)*(1-PV)*0.985*0.55\n",
    "        LSE = PVS\n",
    "#     TS = 1282.71/np.log((666.09/B6R+1))\n",
    "#     print(LSE)\n",
    "    TS = B6T\n",
    "    B6R = 666.09/(np.exp(1282.71/TS))-1\n",
    "    GAM = 1/(14387*B6R/TS**2*(11.45**4*B6R/(1.19104*10**8)+1/11.45))\n",
    "    DEL = -GAM*B6R+TS\n",
    "    w = pwv\n",
    "    F1 = 0.09172*w**2-0.09894*w+1.09659\n",
    "    F2 = -0.71656*w**2-0.64218*w-0.17183\n",
    "    F3 = -0.03503*w**2+1.54063*w-0.46434\n",
    "    TSC = GAM*((F1*B6R+F2)/LSE+F3)+DEL\n",
    "#     plt.contourf(TSC,cmap='gray')\n",
    "#     plt.colorbar()\n",
    "    return TSC\n",
    "def DrawByNgl(nplot,lat,lon,sitename):\n",
    "    boxlat1 = np.array([33.06429,29.7645,\n",
    "             30.7750,28.3581,31.926])\n",
    "    boxlon1 = np.array([91.94256,94.7384,\n",
    "                 90.9885,86.9464,91.716])\n",
    "    txt1 = np.array([\"D105\",\"Linzh\",\"NamCo\",\"QOMO\",\"MS3478\"])\n",
    "\n",
    "\n",
    "    site_info = DataFrame(data=[boxlat1,boxlon1],index=[\"Lat\",\"Lon\"],columns=txt1)\n",
    "    shppath = r'/data/wx_data/Tibet_shape/qingzang.shp'\n",
    "    shpf = Nio.open_file(shppath, \"r\")\n",
    "    shp_lon = shpf.variables[\"x\"][:]\n",
    "    shp_lat = shpf.variables[\"y\"][:]\n",
    "    min_shp_lat = min(shp_lat)\n",
    "    max_shp_lat = max(shp_lat)\n",
    "    min_shp_lon = min(shp_lon)\n",
    "    max_shp_lon = max(shp_lon)\n",
    "    print(min_shp_lat,max_shp_lat,min_shp_lon,max_shp_lon)\n",
    "    ws_id  = Ngl.get_workspace_id()\n",
    "    srlist = Ngl.Resources()\n",
    "    srlist.wsMaximumSize = 1000000000\n",
    "    Ngl.set_values(ws_id,srlist)\n",
    "    rlist = Ngl.Resources()\n",
    "    wks_type = \"png\"\n",
    "    rlist.wkWidth = 3000\n",
    "    rlist.wkHeight = 1000\n",
    "    pngname = \"/home/wx/Jupyter_script/jupyter/LST\"+sitename\n",
    "    wks = Ngl.open_wks(wks_type,pngname,rlist)\n",
    "    cnres = Ngl.Resources()         \n",
    "    cnres.gsnScalarContour  = True\n",
    "    cnres.nglDraw           = False\n",
    "    cnres.nglFrame          = False\n",
    "    cnres.cnFillOn          = True     \n",
    "    cnres.cnLinesOn         = False         # turn off contour lines\n",
    "    cnres.cnLineLabelsOn    = False         # turn off line labels\n",
    "    cnres.cnFillPalette     = \"temp_diff_18lev\"\n",
    "#     cnres.cnFillPalette     = \"MPL_BrBG\"\n",
    "    # cnres.cnLevelSelectionMode=\"ExplicitLevels\"\n",
    "    # cnres.cnLevelSpacingF   = 0.05              # contour level spacing  # can speed up plotting.\n",
    "    # cnres.cnLevels          = np.linspace(0,1,10)\n",
    "    cnres.cnLevelSelectionMode=\"ManualLevels\"\n",
    "    cnres.tmXBLabelFontHeightF   = 0.035\n",
    "    cnres.tmYLLabelFontHeightF   = 0.035\n",
    "    cnres.cnMaxLevelValF        = 320\n",
    "    cnres.cnMinLevelValF        = 240\n",
    "    cnres.cnLevelSpacingF       = 5\n",
    "    cnres.cnFillMode        = \"RasterFill\"        # These two resources\n",
    "    cnres.mpDataBaseVersion     = \"MediumRes\"\n",
    "    cnres.sfMissingValueV   = -999\n",
    "    cnres.mpOutlineOn           = True         # Turn on map outlines\n",
    "    cnres.mpOutlineBoundarySets = \"National\"\n",
    "    # cnres.mpProjection = 'Mercator'\n",
    "    cnres.mpLimitMode       = \"LatLon\"\n",
    "    cnres.mpPerimOn       = True            # Turn on map perimeter.\n",
    "    cnres.mpGridAndLimbOn = False           # Turn off map grid.\n",
    "    cnres.pmLabelBarDisplayMode = \"Never\" \n",
    "    lnres                   = Ngl.Resources()\n",
    "    lnres.gsLineColor       = \"black\"\n",
    "    lnres.gsLineThicknessF  = 3.0            # 3x as thick\n",
    "    data = []\n",
    "    path = r'/data/wx_data/BYSJ/LST/'+sitename+\"/\"\n",
    "    dirs = os.listdir(path)\n",
    "    files = np.array(dirs)\n",
    "    for i in files:\n",
    "        fdata = np.loadtxt(path+i,dtype='float64',delimiter=',')\n",
    "        data.append(Insertion(fdata))\n",
    "    print(nplot)\n",
    "    plots = []\n",
    "    for i in range(0,nplot):\n",
    "        cnres.sfXArray      = np.flipud(lon)\n",
    "        cnres.sfYArray      = np.flipud(lat)\n",
    "        cnres.mpMinLatF     = lat.min()\n",
    "        cnres.mpMaxLatF     = lat.max()\n",
    "        cnres.mpMinLonF     = lon.min()\n",
    "        cnres.mpMaxLonF     = lon.max()\n",
    "        plotdata = Fillna(data[i])\n",
    "        plti = Ngl.contour_map(wks,plotdata,cnres)\n",
    "        mkres = Ngl.Resources()\n",
    "        mkres.gsMarkerIndex = 1\n",
    "        mkres.gsMarkerSizeF = 23\n",
    "        mkres.gsMarkerColor = \"black\"\n",
    "        tres = Ngl.Resources()\n",
    "        tres.txFontHeightF = 0.030\n",
    "        tres.txFontColor   = \"black\"\n",
    "        tres.txFont        = \"helvetica-bold\"\n",
    "        x = site_info.iloc[1].values\n",
    "        y = site_info.iloc[0].values\n",
    "        for j in range(0,site_info.columns.size):\n",
    "            text = site_info.columns.values[j]\n",
    "            tx = x[j]+0.1\n",
    "            ty = y[j]+0.1\n",
    "#             Ngl.add_text(wks,plti,text,tx,ty,tres)\n",
    "        Ngl.add_polymarker(wks,plti,x,y,mkres)\n",
    "        Ngl.add_polyline(wks, plti, shp_lon, shp_lat, lnres)\n",
    "        plots.append(plti)\n",
    "    panelres                            = Ngl.Resources()\n",
    "    panelres.nglPanelYWhiteSpacePercent = 3.\n",
    "    panelres.nglPanelXWhiteSpacePercent = 3.\n",
    "    panelres.nglPanelLabelBar                 = True     # Turn on panel labelbar\n",
    "    panelres.nglPanelLabelBarLabelFontHeightF = 0.012    # Labelbar font height\n",
    "    panelres.nglPanelLabelBarHeightF          = 0.0850   # Height of labelbar\n",
    "    panelres.nglPanelLabelBarWidthF           = 0.700    # Width of labelbar\n",
    "    panelres.lbLabelFont                      = \"helvetica-bold\" # Labelbar font\n",
    "    panelres.lbBoxEndCapStyle                 = \"TriangleBothEnds\"\n",
    "    panelres.nglPanelTop                      = 0.935\n",
    "    panelres.nglPanelFigureStrings            = list(map(chr,range(65, 91)))\n",
    "    panelres.nglPanelFigureStringsFontHeightF =  0.015\n",
    "    panelres.nglPanelFigureStringsJust        = \"BottomLeft\"\n",
    "    Ngl.panel(wks,plots[0:nplot],[2,nplot//2+1],panelres) \n",
    "    Ngl.end()\n",
    "    print(\"Pannel Drew\")\n",
    "def Insertion(data):\n",
    "    ex = pd.DataFrame(data)\n",
    "    ex = ex.fillna(method='pad',limit=5)\n",
    "    return ex.values\n",
    "def Fillna(data):\n",
    "    ex = pd.DataFrame(data)\n",
    "    ex = ex.fillna(-999)\n",
    "    return ex.values\n",
    "def Get_BD(dataset,coors):\n",
    "    lat ,lon = GetCoor(dataset)\n",
    "    BD = find_bd(dataset.ReadAsArray(),lat,lon,coors)\n",
    "    return BD\n",
    "if __name__ =='__main__':\n",
    "    sitename = 'MS3478R'\n",
    "    coors = [31.22623,91.78328]\n",
    "    path = r'/data/wx_data/BYSJ/'+sitename+'/'\n",
    "    dirs = os.listdir(path)\n",
    "    files = np.array(dirs)\n",
    "    para = np.loadtxt(path+sitename+'.txt',dtype=bytes).astype(str) \n",
    "    nplot = 0\n",
    "    n=0\n",
    "    TSA = []\n",
    "    for i in files:\n",
    "        if (i.split('-')[0]==\"2008\"):\n",
    "            dataf=path+i\n",
    "            pwvf = path+'pwv/'+i.split('.')[0]+'pwv.tif'\n",
    "            dataset = gdal.Open(dataf)\n",
    "            lats,lons = GetCoor(dataset)\n",
    "#             pwv = gdal.Open(pwvf)\n",
    "#             pwvdata = pwv.ReadAsArray()\n",
    "            date = i.split(\".\")[0]\n",
    "            time = str(para[n]).split(\"T\")[1]    \n",
    "            PWVFP = \"/data/wx_data/BYSJ/PWV/\"+sitename+'/'+i.split(\".\")[0]+'pwv.txt'\n",
    "            if not os.path.exists(PWVFP):\n",
    "                A = Get_PWV_Array(date,time,dataset)\n",
    "                np.savetxt(PWVFP, A,fmt='%f',delimiter=',')\n",
    "            else:\n",
    "                A = np.loadtxt(PWVFP,delimiter = \",\",dtype = \"float64\")\n",
    "            TS = Calc(dataset,A,para[n])\n",
    "#             np.savetxt(\"/data/wx_data/BYSJ/LST/\"+sitename+'/'+i.split(\".\")[0]+'.txt', TS,fmt='%f',delimiter=',')\n",
    "#             print(i,\"Saved\")\n",
    "#             print(time)\n",
    "            pwvd = Get_PWV(date,time,coors)\n",
    "#             print(A)\n",
    "#             dataNamco = np.array([[2298,2269,2747],[2066,2253,2784],[3818,3136,2709],[3399,2684,2690],[0,1,0]])\n",
    "#             dataqomo = \n",
    "#             BD = dataNamco[n]\n",
    "            BD = Get_BD(dataset,coors)\n",
    "            LSTS = CalcS(BD,pwvd)\n",
    "            hour = time.split(\":\")[0]\n",
    "            minu = time.split(\":\")[1]\n",
    "            timem = hour+\":\"+minu\n",
    "            print(date,timem,LSTS)\n",
    "            n = n+1\n",
    "            nplot = nplot +1\n",
    "#     DrawByNgl(nplot,lats,lons,sitename)\n",
    "#     print(TSA)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namco\n",
      "275.95561666666663\n",
      "-9726.75\n",
      "-9726.75\n",
      "-9726.75\n",
      "276.6799\n",
      "Linzhi\n",
      "289.72799999999995\n",
      "290.72965\n",
      "288.4513833333333\n",
      "284.0371666666666\n",
      "Qomo\n",
      "277.41839999999996\n",
      "287.02099999999996\n",
      "295.04966666666667\n",
      "295.70059999999995\n",
      "307.0169333333333\n",
      "293.849\n",
      "288.693\n",
      "282.09751666666665\n",
      "286.6400333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sitenamesT = ['Namco','Linzhi','Qomo']\n",
    "sitenamesTSFC = ['D105','MS3478L','MS3478R']\n",
    "for sitename in sitenamesT:\n",
    "    print(sitename)\n",
    "    path = r'/data/wx_data/BYSJ/'+sitename+'/'\n",
    "    para = np.loadtxt(path+sitename+'.txt',dtype=bytes).astype(str) \n",
    "    sitepath = r'/data/wx_data/BYSJ/sitedata/'\n",
    "    sdata = pd.read_csv(sitepath+sitename+\".csv\")\n",
    "    columns = sdata.columns\n",
    "    sdata.columns=[x.strip() for x in columns if x.strip() != '']\n",
    "#     print(sdata.columns)\n",
    "    for i in para:\n",
    "        date = str(i).split(\"T\")[0]\n",
    "        month = int(date.split(\"-\")[1])\n",
    "        day = int(date.split(\"-\")[2])\n",
    "        time = str(i).split(\"T\")[1]\n",
    "        hour = int(time.split(\":\")[0])\n",
    "        minu = int(time.split(\":\")[1])\n",
    "#         print(month,day,hour,minu)\n",
    "        smdata = sdata[sdata['month'].isin([int(month)])]\n",
    "        smddata = smdata[smdata['day'].isin([int(day)])]\n",
    "        smdhdata = smddata[smddata['hour'].isin([int(hour+8)])]\n",
    "        smdhdata.reset_index(drop=True, inplace=True)\n",
    "        if(minu<30):\n",
    "            LSTRU = smdhdata.loc[0,'Ts']\n",
    "            LSTRL = smdhdata.loc[1,'Ts']\n",
    "        else:\n",
    "            LSTRU = smdhdata.loc[1,'Ts']\n",
    "            smdhdata = smddata[smddata['hour'].isin([int(hour+9)])]\n",
    "            smdhdata.reset_index(drop=True, inplace=True)       \n",
    "            LSTRL = smdhdata.loc[0,'Ts']\n",
    "        LST = LSTRU+(LSTRL-LSTRU)*minu/60 + 273.15\n",
    "        print(LST)\n",
    "#         LSTRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.nohup.out.swp',\n",
       " 'drought_indices',\n",
       " 'sm',\n",
       " 'TP_image',\n",
       " 'public_use',\n",
       " 'ESA_CCI_SMv4.4',\n",
       " 'MOD11C1',\n",
       " 'MOD09CMG',\n",
       " 'ERA5',\n",
       " 'MOD09GA',\n",
       " 'MOD11A1',\n",
       " 'atoms-chemis-phis',\n",
       " 'cml',\n",
       " 'MOD09GA_MOSAIC',\n",
       " 'MOD11A1_MOSAIC']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"/data/cml_data/\"\n",
    "os.listdir(file)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "NGL",
   "language": "python",
   "name": "pyn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
